{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vehicle Statistics â€” A High Level Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 42, saw 37\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load DF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/DHE42/sprint4project/blob/main/vehicles_us.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m vehicles_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print head of data\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHead of Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 42, saw 37\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Load DF\n",
    "vehicles_df = pd.read_csv('/Users/dianuselvenbough/Desktop/vehicles_us.csv')\n",
    "\n",
    "#print head of data\n",
    "print('Head of Data')\n",
    "print(vehicles_df.head())\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from calling head that the columns of the dataset entail price, model year, model, condition, cylinders, fuel, odomoeter/transmission, type, paint color, four wheel drive status, date datat was posted, and amoutn of days listed before the vehicle was bought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicles Info\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vehicles_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print info\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVehicles Info\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(vehicles_df\u001b[38;5;241m.\u001b[39minfo())\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vehicles_df' is not defined"
     ]
    }
   ],
   "source": [
    "#print info\n",
    "print('Vehicles Info')\n",
    "print(vehicles_df.info())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 51,525 columns overall. Out of these columns, price, model, condition, fuel, transmission, type, date_posted, and days_listed are all filled out. model_year only has 47,906 values of 51,525 filled out, meaning that there are 3,619 null values in the column. Cylinders has 46,265 values filled out, meaning there are 5,260 blank values. Odometer has 43,633 values, meaning there are 7,892 null values. Paint color only has 42,258 filled out, meaning there are 9,267 null values. is_4wd only has 25,572, meaning there are 25,953 null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print describe\n",
    "print('Vehicles Describe')\n",
    "print(vehicles_df.describe())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the mean and the standard deviation that the data is widely dispersed, especially with the minimum value for price being 1 and the max being 375,000. Most of the cars were produced in 2009. Just under 70% of the cars are between four and eight cylinders. The odometer readings on the cars are highly spread out as well. Assuming null values mean no four wheel drive, then about 49% of the cars have four wheel drive. Just under 70% of the cars were listed between 11 and 70 days, with large spread of the data, indicating that there is high variablity in what what characteristics indicate a car will sell easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model year, paint color, cylinders, and odometer readings are very important for analyzing car sells data. Therefore, the rows with NaN values for that data must be jettisoned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of rows with missing data\n",
    "vehicles_df = vehicles_df.dropna(subset=['model_year', 'paint_color', 'cylinders', 'odometer'])\n",
    "\n",
    "# Replace NaN values in is_4wd with 0\n",
    "vehicles_df['is_4wd'] = vehicles_df['is_4wd'].fillna(0)\n",
    "\n",
    "\n",
    "print(vehicles_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a set of workable data, it's wise to make sure all data types in the dataframe make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprint info for reference\n",
    "print('Vehicles Info')\n",
    "print(vehicles_df.info())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_year, cylinders, and odometer should all be stored as int64 to reduce space, and because there are no necessary decimals in the numerical values of those columns. \n",
    "\n",
    "model, condition, fuel, transmission, type, and paint_color should all be stored as strings.\n",
    "\n",
    "is_4wd should be stored as a boolean.\n",
    "\n",
    "date_posted should be stored as datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting model_year to int\n",
    "vehicles_df['model_year'] = vehicles_df['model_year'].astype(int)\n",
    "\n",
    "# Converting odometer to int\n",
    "vehicles_df['odometer'] = vehicles_df['odometer'].astype(int)\n",
    "\n",
    "# Converting cylinders to int\n",
    "vehicles_df['cylinders'] = vehicles_df['cylinders'].astype(int)\n",
    "\n",
    "# Converting model to string\n",
    "vehicles_df['model'] = vehicles_df['model'].astype('string')\n",
    "\n",
    "# Converting condition to string\n",
    "vehicles_df['condition'] = vehicles_df['condition'].astype('string')\n",
    "\n",
    "#Converting fuel to string\n",
    "vehicles_df['fuel'] = vehicles_df['fuel'].astype('string')\n",
    "\n",
    "# Converting transmission to string\n",
    "vehicles_df['transmission'] = vehicles_df['transmission'].astype('string')\n",
    "\n",
    "# Converting type to string\n",
    "vehicles_df['type'] = vehicles_df['type'].astype('string')\n",
    "\n",
    "# Converting paint_color to string\n",
    "vehicles_df['paint_color'] = vehicles_df['paint_color'].astype('string')\n",
    "\n",
    "# Converting is_4wd to bool\n",
    "vehicles_df['is_4wd'] = vehicles_df['is_4wd'].astype(bool)\n",
    "\n",
    "# Converting date_posted to datetime\n",
    "vehicles_df['date_posted'] = pd.to_datetime(vehicles_df['date_posted'])\n",
    "\n",
    "# Reprint info to check changes\n",
    "print('Vehicles Info')\n",
    "print(vehicles_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, we now have 29,916 values that allow us to analyze the dataset reliably. The next step is to go through model, condition, fuel, transmission, type, and paint_color to make sure that all the values for the specific data are easy to put into conversation together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in each string column\n",
    "print('Unique Values')\n",
    "print()\n",
    "print(\"Number of Models:\", (vehicles_df['model'].nunique()))\n",
    "print(\"Model:\")\n",
    "for model in sorted(vehicles_df['model'].str.strip().str.lower().unique()):\n",
    "    print(\"-\", model)\n",
    "print()\n",
    "\n",
    "print(\"Number of Conditions:\", (vehicles_df['condition'].nunique()))\n",
    "print(\"Condition:\")\n",
    "for condition in sorted(vehicles_df['condition'].str.strip().str.lower().unique()):\n",
    "    print(\"-\", condition)\n",
    "print()\n",
    "\n",
    "print(\"Number of Fuel Types:\", (vehicles_df['fuel'].nunique()))\n",
    "print(\"Fuel Types:\")\n",
    "for fuel in sorted(vehicles_df['fuel'].str.strip().str.lower().unique()):\n",
    "    print(\"-\", fuel)\n",
    "print(f\"Count of Other Kinds of Fuel Types: {vehicles_df['fuel'].str.strip().str.lower().value_counts().loc['other']} of 29,916 values\")\n",
    "print()\n",
    "\n",
    "print(\"Number of Transmission Types:\", (vehicles_df['transmission'].nunique()))\n",
    "print(\"Transmission Types:\")\n",
    "for transmission in sorted(vehicles_df['transmission'].str.strip().str.lower().unique()):\n",
    "    print(\"-\", transmission)\n",
    "print(f\"Count of Other Kinds of Transmissions: {vehicles_df['transmission'].str.strip().str.lower().value_counts().loc['other']} of 29,916 values\")\n",
    "print()\n",
    "\n",
    "print(\"Number of Vehicle Types:\", (vehicles_df['type'].nunique()))\n",
    "print(\"Vehicle Types:\")\n",
    "for vehicle_type in sorted(vehicles_df['type'].str.strip().str.lower().unique()):\n",
    "    print(\"-\", vehicle_type)\n",
    "print()\n",
    "\n",
    "print(\"Number of Paint Colors:\", (vehicles_df['paint_color'].nunique()))\n",
    "print(\"Paint Colors:\")\n",
    "for paint_color in sorted(vehicles_df['paint_color'].str.strip().str.lower().unique()):\n",
    "    print(\"-\", paint_color)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transmission and fuel columns have a negligible amount of 'other' values, so we will jettison those to aid in specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where \"other\" is the value for fuel or transmission\n",
    "vehicles_df = vehicles_df[(vehicles_df['fuel'] != 'other') & (vehicles_df['transmission'] != 'other')]\n",
    "\n",
    "# Check to see if 'other' appears in fuel or transmission\n",
    "print('Fuel and Transmission Check')\n",
    "print()\n",
    "print('Other Fuel:', vehicles_df['fuel'].str.strip().str.lower().value_counts().get('other', 0))\n",
    "print('Other Transmission:', vehicles_df['transmission'].str.strip().str.lower().value_counts().get('other', 0))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to assist our client in making the most sales, we want to find out what some factors are that can impact how quickly a car sales, as well as for what price. Therefore, we want to consider price in relationship to all the factors that are available. Let's start by figuring out which decade of mode_year had the highest prices associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decade bins\n",
    "bins = np.arange(1900, 2030, 10)  # Decade bins from 1900 to 2020\n",
    "labels = [f\"{int(start)}s\" for start in bins[:-1]]  # Create labels for each decade\n",
    "\n",
    "# Assign each model_year to a decade bin\n",
    "vehicles_df['decade'] = pd.cut(vehicles_df['model_year'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Create a histogram using Plotly Express\n",
    "fig = px.histogram(vehicles_df, x=\"price\", color=\"decade\",\n",
    "                   nbins=400, barmode=\"stack\",\n",
    "                   title=\"Histogram of Price Distribution by Decade\",\n",
    "                   labels={\"price\": \"Price ($)\", \"decade\": \"Decade\"},\n",
    "                   opacity=0.7)\n",
    "\n",
    "# Update the x axis to only show prices 0 to 50,000, since the majority of prices are below 50,000\n",
    "fig.update_xaxes(range=[0, 60000])\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decade bins\n",
    "bins = np.arange(1900, 2030, 10)  # Decade bins from 1900 to 2020\n",
    "labels = [f\"{int(start)}s\" for start in bins[:-1]]  # Create labels for each decade\n",
    "\n",
    "# Assign each model_year to a decade bin\n",
    "vehicles_df['decade'] = pd.cut(vehicles_df['model_year'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Ensure models are sorted alphabetically before plotting\n",
    "vehicles_df = vehicles_df.sort_values(by='model')\n",
    "\n",
    "# Create a histogram using Plotly Express, using model as color\n",
    "fig_1 = px.histogram(vehicles_df, x=\"price\", color=\"model\",\n",
    "                   nbins=400, barmode=\"stack\",\n",
    "                   title=\"Histogram of Price Distribution by Model (Alphabetized)\",\n",
    "                   labels={\"price\": \"Price ($)\", \"model\": \"Vehicle Model\"},\n",
    "                   opacity=0.7,\n",
    "                   category_orders={\"model\": sorted(vehicles_df['model'].unique())})  # Ensures models are in alphabetical order\n",
    "\n",
    "# Update the x-axis to only show prices from 0 to 60,000\n",
    "fig_1.update_xaxes(range=[0, 60000])\n",
    "\n",
    "# Show the plot\n",
    "fig_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2010s have the highest number of vehicles in the dataset. In addition, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a histogram using Plotly Express\n",
    "fig_2 = px.histogram(vehicles_df, x=\"price\", color=\"paint_color\",\n",
    "                   title=\"Price Distribution by Paint Color\",\n",
    "                   labels={\"price\": \"Price ($)\", \"paint_color\": \"Paint Color\"},\n",
    "                   opacity=0.7,\n",
    "                   barmode=\"stack\")  \n",
    "\n",
    "# Make x-axis 0-60k\n",
    "fig_2.update_xaxes(range=[0, 60000])\n",
    "\n",
    "# Show the plot\n",
    "fig_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot of Price and Model Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_3 = px.scatter(vehicles_df, \n",
    "                 x='model_year', \n",
    "                 y='price', \n",
    "                 title='Vehicle Price vs. Model Year',\n",
    "                 labels={'model_year': 'Model Year', 'price': 'Price'},\n",
    "                 trendline=\"ols\")\n",
    "\n",
    "# Change trendline to red\n",
    "fig_3.update_traces(selector=dict(name=\"trendline\"), line=dict(color='red'))\n",
    "\n",
    "#display plot\n",
    "fig_3.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
